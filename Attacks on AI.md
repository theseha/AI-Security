📅 2025.07.17

# 🧠 AI를 겨냥한 공격이란?

AI를 기존의 시스템에 도입하면, 기존 사이버 공격과는 다른 유형의 **AI 특화 공격(adversarial attacks)**에 노출될 수 있습니다. 공격자들이 사용하는 기법은 전통적인 사이버 보안 기법과 다르며 독특한 특징을 가집니다.

기업, 조직 또는 연구팀이 이러한 AI 대상 공격을 이해하게 되면, **AI 통합으로부터 발생하는 보안 리스크를 완화하는 대응 전략 수립**이 가능해집니다.

---

## 🚨 AI 공격을 이해하는 데 필수적인 세 가지 개념

AI를 활용한 시스템에 가해질 수 있는 다양한 공격을 이해하기 위해, 공격자가 활용할 수 있는 다음 세 가지 주요 요소를 소개합니다:

1. **AI 액세스 시점 (AI Access Time)**  
2. **AI 액세스 지점 (AI Access Points)**  
3. **시스템 정보 보유 수준 (System Knowledge)**

---

### 1. 🕒 AI 액세스 시점 (Access Time)

AI 시스템은 **훈련 단계(Training)**와 **추론 단계(Inference)** 두 개의 주요 단계로 나뉩니다:

- **훈련 단계**는 데이터 수집, 전처리, 학습 및 성능 검증의 과정을 포함합니다.
- **추론 단계**는 모델 배포 이후 진행되며, 사용자가 입력(쿼리)을 제공하면 모델이 예측값 혹은 생성 결과를 반환합니다.

공격자는 이 두 단계 중 어느 시점에서든 AI 시스템을 표적으로 삼을 수 있습니다.

---

### 2. 🔌 AI 액세스 지점 (Access Points)

AI 시스템에 접근하는 지점은 **디지털 방식** 또는 **물리적 방식**으로 나눌 수 있습니다:

- **디지털 접근**은 대표적으로 **API**를 통해 이루어집니다. 공격자는 쿼리를 보내고 모델의 반응을 분석하여 AI 시스템을 조작하려 합니다.
  
- **물리적 접근**은 현실 세계에서 **데이터 센서 또는 수집 장비에 직접 영향을 미치는 방식**입니다. 예를 들어, 감시 카메라에 스티커를 붙여 모델 인식 결과를 왜곡시키는 방식이 이에 속합니다.

---

### 3. 🧩 시스템 정보 보유 수준 (System Knowledge)

공격자가 AI 시스템에 대해 **얼마나 많은 정보를 갖고 있는가**에 따라 공격 가능성과 전략이 달라집니다:

- **화이트박스(White-box):** 모델 아키텍처, 가중치, 학습 데이터 등을 모두 알고 있음.
- **블랙박스(Black-box):** 모델 내부를 모른 채, 입력과 출력값만 확인할 수 있음. API 접근 시 대표적으로 나타나는 유형입니다.

---

<img width="3488" height="1940" alt="image" src="https://github.com/user-attachments/assets/458bae11-0e6a-49bc-9f0d-be522d0ab34e" />


## 🔓 AI 시스템 공격 유형과 효과 요약

다음 표는 대표적인 AI 공격 유형들과 그로 인해 AI 시스템에서 발생할 수 있는 잠재적 피해를 요약한 것입니다 (자세한 목록은 [MITRE ATLAS Matrix](https://atlas.mitre.org/) 참고).

| 공격 유형 | 설명 |
|-----------|------|
| **데이터 중독 (Poisoning Attack)** | 훈련 데이터를 조작하여 **특정 입력에 대해 공격자가 원하는 출력**을 하도록 모델을 왜곡합니다. 일종의 백도어(backdoor)를 삽입할 수 있습니다. |
| **회피 공격 (Evasion Attack)** | 적대적 입력(Adversarial Input)을 만들어 **모델에서 잘못된 응답을 유도**합니다. 타겟형 공격(특정 분류 유도) 또는 비타겟형 공격(아무 잘못된 결과면 됨)으로 구분됩니다. |
| **기능 추출 (Functional Extraction)** | 반복적 쿼리를 통해 **모델과 유사한 사본을 추출**합니다. 이렇게 복제한 모델을 기반으로 추가 공격(역공학, 분석 등)이 이어질 수 있습니다. |
| **역추론 공격 (Inversion Attack)** | 학습 데이터의 민감한 속성이나 원본 데이터를 **역으로 유추하거나 복원**합니다. 이 공격은 단독으로도 해롭지만, 타 공격에 활용될 수도 있습니다. |
| **프롬프트 인젝션 (Prompt Injection Attack)** | 악의적 프롬프트를 LLM 계열 모델에 입력해 **본래 지시를 무시하도록 유도**하고 공격자의 명령을 따르게 만듭니다. |
| **전통 사이버 공격 (Traditional Cyber Attack)** | AI와 관계된 서버, 데이터 저장소, API 키, 모델 파일 등을 대상으로 **기존의 사이버 공격 기법(TTPs)**을 활용하는 방식입니다. 이는 AI 모델 그 자체보다 **AI 인프라**를 목표로 합니다. |

---

## 📌 요약

AI 시스템이 점점 더 많이 활용되며, 이에 대한 공격도 정교해지고 복잡해지고 있습니다.  
조직은 **AI의 전체 수명 주기(훈련 + 추론)와 내부 구조, 시스템 노출 지점**을 고려한 다층적인 보안 전략을 수립해야 하며,  
MITRE ATLAS 같은 프레임워크를 통해 구조적인 공격-방어 트레이스 및 대응 계획 수립이 가능해집니다.

---

<sub>출처: [MITRE ATLAS - AI Security 101](https://atlas.mitre.org/resources/ai-security-101)  
