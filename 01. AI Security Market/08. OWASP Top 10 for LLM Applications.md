📅 2025.07.17

# 🛠️ LLM 애플리케이션 아키텍처와 위협 모델링  
*LLM Application Architect and Threat Modeling*

---

대형 언어 모델(LLM, Large Language Model) 기반 애플리케이션의 보안을 강화하기 위해서는, **아키텍처 설계와 위협 모델링(threat modeling)**이 핵심 요소로 작용합니다.  
이는 단순히 코드 수준의 보안 패치가 아니라, LLM이 통합된 **시스템 전체의 구조적 위험을 이해하고 설계 시점부터 방어 전략을 반영하는 접근**입니다.

<img width="695" height="372" alt="LLM architecture and threat modeling" src="https://github.com/user-attachments/assets/d87f5dd4-ac18-499f-934a-4801fb934110" />

## 🚨 OWASP LLM Top 10 (2025) 주요 위협 항목 요약

아래는 2025년 OWASP에서 발표한 **대형 언어 모델(LLM) 기반 애플리케이션 보안 위협 Top 10**의 핵심 내용을 요약한 것입니다.  
이는 아키텍처 설계 및 위협 모델링 단계에서 반드시 고려되어야 할 보안 이슈들로, **모든 LLM 활용 서비스에 걸쳐 공통적으로 적용되는 위험 요소들**입니다.

---

### 🔐 LLM01: 프롬프트 인젝션 (Prompt Injection)

- 사용자의 입력이 모델의 **의도된 동작을 교란하거나 우회**하도록 만들 수 있는 취약점입니다.
- 입력 내용이 사람 눈에는 잘 보이지 않더라도, 모델이 이해한다면 공격이 가능.
- **간접 프롬프트 인젝션 기법**은 개인 정보 탈취, 악성 사이트 유도, 보안 가이드라인 무력화 등을 유발할 수 있음.
- RAG나 파인튜닝 같은 기술이 사용되더라도, 프롬프트 인젝션을 완전히 방지하지는 못함.
- **프롬프트 인젝션**과 **Jailbreak**는 유사 개념으로, 후자는 모델의 안전장치를 완전히 무력화시키는 것을 지칭.

---

### 🧩 LLM02: 민감 정보 노출 (Sensitive Information Disclosure)

- LLM 출력에 **개인정보(PII), 금융 정보, 의료 기록, 기업 기밀, 인증 정보** 등이 포함될 수 있음.
- 훈련 데이터 관리 미흡 시, 사용자 입력이 학습되어 **민감 정보가 재노출**될 위험 존재.
- **시스템 프롬프트 내부에 민감 정보 포함**하는 것도 위험.
- 데이터 정제 및 시스템 프롬프트 제약 설정이 필요하지만, 인젝션 공격 등으로 우회 가능성 존재.

---

### 🔗 LLM03: 공급망 취약점 (Supply Chain Risks)

- LLM 생태계는 **사전 훈련 모델, 퍼블릭 데이터, 배포 플랫폼** 등 여러 외부 요소에 의존함.
- 외부 구성 요소가 **조작되거나 오염(poisoning)될 위험**이 있음.
- 특히 Hugging Face 등 오픈소스 플랫폼에서 **LoRA, PEFT** 같이 효율적인 파인튜닝 방식 사용 시 리스크 증가.
- 공급망 위험은 **데이터 및 모델 중독(Data/Model Poisoning)** 문제와도 밀접하게 연결됨.

---

### ☠️ LLM04: 데이터 및 모델 중독 (Data and Model Poisoning)

- 훈련, 파인튜닝, 임베딩 단계에서 **악의적으로 조작된 데이터**를 포함시켜 **바이어스, 백도어 삽입, 성능 저하**를 유발할 수 있음.
- 잘 설계된 백도어는 **특정 트리거 입력이 들어올 때만 작동**하므로 탐지하기 어려움.
- **오픈소스 모델 공유 시 악성 코드 삽입**, 악성 pickling 등을 통한 시스템 공격도 포함됨.

---

### 🧯 LLM05: 부적절한 출력 처리 (Improper Output Handling)

- LLM 출력에 대해 **정확한 검증·정제 없이 후속 시스템에 전달**될 경우 발생하는 취약점.
- 이로 인해 XSS, CSRF, SSRF, 권한 상승, 원격 코드 실행 등 현실적인 보안 사고 가능성 존재.

#### 💣 주요 원인

- LLM이 사용자보다 높은 권한을 가진 시스템에 연결된 경우
- 간접 프롬프트 인젝션에 대한 방어 부재
- 써드파티 플러그인 입력 검증 실패
- HTML/JS/SQL 콘텍스트에서의 출력 인코딩 미흡
- 로깅/모니터링 부족
- 무제한 LLM 사용 허용으로 인한 이상 행위 미탐지

---

### 🤖 LLM06: 과도한 자율성 (Excessive Agency)

- LLM이 **플러그인/스크립트/툴** 등을 실행할 수 있게 되면서, 모델에 **행동 권한(agency)**가 부여됨.
- 잘못된 응답, 조작된 입력, 모델의 잘못된 판단(hallucination) 등으로 인해 **예상치 못한 악의적 행동 발생 위험** 존재.

#### 📌 취약 원인

- 과도한 기능 부여  
- 과도한 시스템 접근 권한  
- 사용자 요청 기반의 자동 결정/실행 자율성 부여

---

### 🧵 LLM07: 시스템 프롬프트 유출 (System Prompt Leakage)

- 시스템 프롬프트 내에 포함된 **개발자 지침, 비밀값, 역할 정보** 등이 LLM의 응답을 통해 노출될 수 있음.
- **시스템 프롬프트는 보안 수단이 아니며**, 내부에 비밀 정보(예: API 키, 비밀번호 등)를 포함시켜서는 안 됨.
- 진짜 위험은 정보 노출 자체보다, **프롬프트 기반 권한 제어 방식이 우회될 수 있는 구조에 있음**.

---

### 🔎 LLM08: 벡터 및 임베딩 취약점 (Vector and Embedding Weaknesses)

- RAG(지식 검색 기반 생성 방식) 등을 위해 사용되는 임베딩/벡터 처리 파이프라인 상의 문제로 인해 **민감 정보 노출, 조작된 출력, 악성 콘텐츠 삽입** 등이 발생할 수 있음.
- 벡터 생성/저장/검색의 모든 단계에서 **무결성 보호**가 필요함.

---

### 📉 LLM09: 허위 정보 생성 (Misinformation)

- LLM이 생성하는 **그럴듯하지만 잘못된 정보(hallucination)**는 잘못된 의사결정 유도, 신뢰도 하락, 법적 위험으로 이어질 수 있음.
- 특히, 사용자나 조직이 **LLM의 출력을 맹목적으로 신뢰(overreliance)**할 경우 피해가 커짐.

---

### ♾️ LLM10: 무제한 소비 (Unbounded Consumption)

- 과도한 쿼리나 프롬프트 요청을 통해 **서비스를 고의로 과부하**시키거나 **모델을 복제 및 도용**하려는 공격이 가능.
- 클라우드 기반 LLM의 **고연산 특성**을 이용한 자원 고갈, 서비스 제한, 재정적 피해 위험 존재.

---

> ℹ️ 출처: [OWASP Top 10 for LLM Applications 2025](https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/)
